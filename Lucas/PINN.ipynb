{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(28)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\DeepLearning-PINNs\\Lucas\n",
      "Training data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Lucas/this_script.py\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "# Add the 'functions' folder to the Python path\n",
    "functions_dir = os.path.join(current_dir,'..', 'functions')\n",
    "sys.path.append(functions_dir)\n",
    "functions_dir = os.path.join(current_dir,'..', 'Mads')\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# Now you can import the function\n",
    "from Load_data import custom_csv_parser2, custom_csv_parser\n",
    "from Load_data import data_split\n",
    "\n",
    "pde_keys = ['D1', 'D2', 'I_sc','I_p', 'I_eff', 'G', 'G_sc']\n",
    "patient_keys = ['tau1', 'tau2', 'Ci', 'p2', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "patient_keys_si = ['tau1', 'tau2', 'Ci', 'p2', 'Si', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "\n",
    "def dict_to_vec(X, t):\n",
    "    \"\"\"Converts a dictionary of time series data to a vector\"\"\"\n",
    "    t = t.cpu().numpy().astype(int) if t.numel() > 1 else [int(t.item())]  # Ensure t is a list of integers\n",
    "    X_vec = torch.zeros((len(t), len(pde_keys)), device=device)  # Initialize X_vec with the correct shape\n",
    "    \n",
    "    for i, ti in enumerate(t):\n",
    "        for j, key in enumerate(pde_keys):\n",
    "            value = torch.tensor(X[key][ti], device=device)  # Convert to torch.Tensor\n",
    "            X_vec[i, j] = value\n",
    "    \n",
    "    return X_vec.to(device)\n",
    "scale_vec = torch.tensor([1.56, 1.54, 1.24, 1.24, 0.01, 117.56, 117.48], device=device, dtype=torch.float32)\n",
    "# Use the function\n",
    "data = custom_csv_parser2('../Patient2.csv')\n",
    "parms = custom_csv_parser('../Patient.csv')\n",
    "Si_true = parms['Si']\n",
    "\n",
    "X_train, X_test, ts_train, ts_test, ts = data_split(data)\n",
    "G_true = X_train[\"G\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si0 = 0.01\n",
    "\n",
    "p = 0.4\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    '''Network'''\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1] ) for i in range(len(layers)-1)])\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "        'Initialization'\n",
    "        for i in range(len(layers) - 1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight, gain=1.0)\n",
    "            nn.init.zeros_(self.linears[i].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(0, len(self.linears) - 1):\n",
    "            x = self.linears[i](x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.linears[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdes(u, nn_dt, Si):\n",
    "    pdes = torch.zeros_like(u, device=device)\n",
    "    D1 = u[:, 0]  \n",
    "    D2 = u[:, 1]  \n",
    "    I_sc = u[:, 2]  \n",
    "    I_p = u[:, 3]  \n",
    "    I_eff = u[:, 4]  \n",
    "    G = u[:, 5]  \n",
    "    G_sc = u[:, 6]  \n",
    "    \n",
    "    # Convert parameters to tensors\n",
    "    taum = torch.tensor(parms['taum'], device=device)\n",
    "    tau1 = torch.tensor(parms['tau1'], device=device)\n",
    "    tau2 = torch.tensor(parms['tau2'], device=device)\n",
    "    p2 = torch.tensor(parms['p2'], device=device)\n",
    "    Ci = torch.tensor(parms['Ci'], device=device)\n",
    "    GEZI = torch.tensor(parms['GEZI'], device=device)\n",
    "    EGP0 = torch.tensor(parms['EGP0'], device=device)\n",
    "    Vg = torch.tensor(parms['Vg'], device=device)\n",
    "    tausc = torch.tensor(parms['tausc'], device=device)\n",
    "\n",
    "    ds = torch.zeros_like(u[:,0], device=device)\n",
    "    ds[0] = data['Meal'][0]\n",
    "    us = torch.ones_like(u[:,0], device=device) * 25.04\n",
    "    us[0] = data['Insulin'][0]\n",
    "    \n",
    "    # Example assignment for all rows of pdes\n",
    "    pdes[:, 0] = nn_dt[:, 0] + D1 / taum - ds\n",
    "    pdes[:, 1] = nn_dt[:, 1] - (D1 - D2) / taum\n",
    "    pdes[:, 2] = nn_dt[:, 2] + I_sc / tau1 - us / (tau1 * Ci)\n",
    "    pdes[:, 3] = nn_dt[:, 3] - (I_sc - I_p) / tau2\n",
    "    pdes[:, 4] = nn_dt[:, 4] + p2 * I_eff - p2 * Si * I_p\n",
    "    pdes[:, 5] = nn_dt[:, 5] + (GEZI + I_eff) * G - EGP0 - 1000 * D2 / (Vg * taum)\n",
    "    pdes[:, 6] = nn_dt[:, 6] - (G - G_sc) / tausc\n",
    "\n",
    "    return pdes / scale_vec\n",
    "\n",
    "class PINN():\n",
    "    def __init__(self, layers):\n",
    "        self.iter = 0\n",
    "\n",
    "        self.Si = torch.tensor([Si0], requires_grad=True, device=device)\n",
    "        self.Si = nn.Parameter(self.Si)\n",
    "        self.nn = DNN(layers).to(device)\n",
    "        self.nn.register_parameter('Si', self.Si)\n",
    "\n",
    "    def data_loss(self, ts, data):\n",
    "        u = self.nn(ts)  # Outputs ts x 7 array\n",
    "        loss = 0\n",
    "        for i,key in enumerate(pde_keys):\n",
    "            loss += torch.mean((u[i] - data[key][int(ts[i])])**2)\n",
    "        return loss\n",
    "\n",
    "    def pde_loss(self, ts):\n",
    "        \n",
    "        ts = ts.clone().detach()\n",
    "        ts = ts.requires_grad_(True)\n",
    "        u = self.nn(ts)        \n",
    "        nn_dt = torch.zeros_like(u, device=device)\n",
    "\n",
    "        for i in range(u.shape[1]):\n",
    "            nn_dt[:, i] = autograd.grad(u[:, i], ts, grad_outputs=torch.ones_like(u[:, i]), create_graph=True)[0].squeeze()\n",
    "\n",
    "        pd = pdes(u, nn_dt, self.Si)\n",
    "        loss = nn.MSELoss()(pd, torch.zeros_like(pd))\n",
    "        return loss\n",
    "    \n",
    "    def loss(self, ts, data):\n",
    "        return self.data_loss(ts, data) + self.pde_loss(ts)\n",
    "    \n",
    "    def test(self, t):\n",
    "        #t = t.unsqueeze(0)\n",
    "        X_pred = self.nn.forward(t)\n",
    "        X_true = dict_to_vec(data, t)\n",
    "        print(X_pred.shape)\n",
    "        print(X_true.shape)\n",
    "        error_vec = torch.linalg.norm((X_true-X_pred),2)/torch.linalg.norm(X_true,2)\n",
    "        X_pred = X_pred.cpu().detach().numpy()\n",
    "        return X_pred, error_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([1, 7])\n",
      "Prediction: [-0.57569087 -0.09128979 -0.37735116  0.95070064 -0.39105302  1.4893415\n",
      " -0.25105685] \n",
      " Error: 0.9945842623710632\n",
      "Current guess for Si:  0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "NN = PINN([1, 20, 40, 20, 7])\n",
    "params = list(NN.nn.parameters())\n",
    "optimizer = optim.Adam(NN.nn.parameters(), lr=0.001)\n",
    "\n",
    "'''Test Network works'''\n",
    "pred, err = NN.test(torch.tensor([1], device=device, dtype=torch.float32))\n",
    "print(f\"\"\"Prediction: {pred} \\n Error: {err}\"\"\")\n",
    "print(\"Current guess for Si: \", NN.Si.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Meal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[325], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[323], line 69\u001b[0m, in \u001b[0;36mPINN.loss\u001b[1;34m(self, ts, data)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, ts, data):\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loss(ts, data) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpde_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[323], line 64\u001b[0m, in \u001b[0;36mPINN.pde_loss\u001b[1;34m(self, ts)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     62\u001b[0m     nn_dt[:, i] \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(u[:, i], ts, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u[:, i]), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m---> 64\u001b[0m pd \u001b[38;5;241m=\u001b[39m \u001b[43mpdes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_dt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()(pd, torch\u001b[38;5;241m.\u001b[39mzeros_like(pd))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[1;32mIn[323], line 23\u001b[0m, in \u001b[0;36mpdes\u001b[1;34m(u, nn_dt, Si)\u001b[0m\n\u001b[0;32m     20\u001b[0m tausc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(parms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtausc\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     22\u001b[0m ds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(u[:,\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 23\u001b[0m ds[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMeal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m us \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(u[:,\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25.04\u001b[39m\n\u001b[0;32m     25\u001b[0m us[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsulin\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Meal'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ts_train = torch.tensor(ts_train, device=device, dtype=torch.float32).reshape(-1,1)\n",
    "ts_test = torch.tensor(ts_test, device=device, dtype=torch.float32)\n",
    "epochs = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = NN.loss(ts_train, parms)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Si: {NN.Si.item()}\")\n",
    "\n",
    "print(\"True Si: \", Si_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.564036816889645\n",
      "1.5472147500856661\n",
      "1.2474305980382763\n",
      "1.247415539752733\n",
      "0.010104967942474905\n",
      "117.560994471807\n",
      "117.48980875234228\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
