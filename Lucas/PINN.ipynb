{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\DeepLearning-PINNs\\Lucas\n",
      "Training data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Lucas/this_script.py\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "# Add the 'functions' folder to the Python path\n",
    "functions_dir = os.path.join(current_dir,'..', 'functions')\n",
    "sys.path.append(functions_dir)\n",
    "functions_dir = os.path.join(current_dir,'..', 'Mads')\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# Now you can import the function\n",
    "from Load_data import custom_csv_parser2, custom_csv_parser\n",
    "from Load_data import data_split\n",
    "\n",
    "pde_keys = ['D1', 'D2', 'I_sc','I_p', 'I_eff', 'G', 'G_sc']\n",
    "patient_keys = ['tau1', 'tau2', 'Ci', 'p2', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "patient_keys_si = ['tau1', 'tau2', 'Ci', 'p2', 'Si', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "\n",
    "def dict_to_vec(X, t):\n",
    "    \"\"\"Converts a dictionary of time series data to a vector\"\"\"\n",
    "    t = t.cpu().numpy().astype(int) if t.numel() > 1 else [int(t.item())]  # Ensure t is a list of integers\n",
    "    X_vec = torch.zeros((len(t), len(pde_keys)), device=device)  # Initialize X_vec with the correct shape\n",
    "    \n",
    "    for i, ti in enumerate(t):\n",
    "        for j, key in enumerate(pde_keys):\n",
    "            value = torch.tensor(X[key][ti], device=device)  # Convert to torch.Tensor\n",
    "            X_vec[i, j] = value\n",
    "    \n",
    "    return X_vec.to(device)\n",
    "\n",
    "# Use the function\n",
    "data = custom_csv_parser2('../Patient2.csv')\n",
    "parms = custom_csv_parser('../Patient.csv')\n",
    "Si_true = parms['Si']\n",
    "\n",
    "X_train, X_test, ts_train, ts_test, ts = data_split(data)\n",
    "G_true = X_train[\"G\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si0 = 0.1\n",
    "\n",
    "p = 0.4\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    '''Network'''\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1] ) for i in range(len(layers)-1)])\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "        'Initialization'\n",
    "        for i in range(len(layers) - 1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight, gain=1.0)\n",
    "            nn.init.zeros_(self.linears[i].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(0, len(self.linears) - 1):\n",
    "            x = self.linears[i](x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.linears[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdes(u, nn_dt, Si):\n",
    "    pdes = torch.zeros_like(u, device=device)\n",
    "    D1 = u[:, 0]  # Example, assuming D1 is the first column of u\n",
    "    D2 = u[:, 1]  # Example, assuming D2 is the second column of u\n",
    "    I_sc = u[:, 2]  # Example, assuming I_sc is the third column of u\n",
    "    I_p = u[:, 3]  # Example, assuming I_p is the fourth column of u\n",
    "    I_eff = u[:, 4]  # Example, assuming I_eff is the fifth column of u\n",
    "    G = u[:, 5]  # Example, assuming G is the sixth column of u\n",
    "    G_sc = u[:, 6]  # Example, assuming G_sc is the seventh column of u\n",
    "    \n",
    "    # Convert parameters to tensors\n",
    "    taum = torch.tensor(parms['taum'], device=device)\n",
    "    tau1 = torch.tensor(parms['tau1'], device=device)\n",
    "    tau2 = torch.tensor(parms['tau2'], device=device)\n",
    "    p2 = torch.tensor(parms['p2'], device=device)\n",
    "    Ci = torch.tensor(parms['Ci'], device=device)\n",
    "    GEZI = torch.tensor(parms['GEZI'], device=device)\n",
    "    EGP0 = torch.tensor(parms['EGP0'], device=device)\n",
    "    Vg = torch.tensor(parms['Vg'], device=device)\n",
    "    tausc = torch.tensor(parms['tausc'], device=device)\n",
    "\n",
    "    d = 0\n",
    "    meal = 0\n",
    "    \n",
    "    # Example assignment for all rows of pdes\n",
    "    pdes[:, 0] = nn_dt[:, 0] + D1 / taum - d\n",
    "    pdes[:, 1] = nn_dt[:, 1] - (D1 - D2) / taum\n",
    "    pdes[:, 2] = nn_dt[:, 2] + I_sc / tau1 - meal / (tau1 * Ci)\n",
    "    pdes[:, 3] = nn_dt[:, 3] - (I_sc - I_p) / tau2\n",
    "    pdes[:, 4] = nn_dt[:, 4] + p2 * I_eff - p2 * Si * I_p\n",
    "    pdes[:, 5] = nn_dt[:, 5] + (GEZI + I_eff) * G - EGP0 - 1000 * D2 / (Vg * taum)\n",
    "    pdes[:, 6] = nn_dt[:, 6] - (G - G_sc) / tausc\n",
    "    \n",
    "    return pdes\n",
    "\n",
    "class PINN():\n",
    "    def __init__(self, layers):\n",
    "        self.iter = 0\n",
    "\n",
    "        self.Si = torch.tensor([Si0], requires_grad=True, device=device)\n",
    "        self.Si = nn.Parameter(self.Si)\n",
    "        self.nn = DNN(layers).to(device)\n",
    "        self.nn.register_parameter('Si', self.Si)\n",
    "\n",
    "    def data_loss(self, ts, data):\n",
    "        u = self.nn(ts)  # Outputs ts x 7 array\n",
    "        loss = 0\n",
    "        for i,key in enumerate(pde_keys):\n",
    "            loss += torch.mean((u[i] - data[key][int(ts[i])])**2)\n",
    "        return loss\n",
    "\n",
    "    def pde_loss(self, ts):\n",
    "        \n",
    "        ts = ts.clone().detach()\n",
    "        ts = ts.requires_grad_(True)\n",
    "        u = self.nn(ts)        \n",
    "        nn_dt = torch.zeros_like(u, device=device)\n",
    "\n",
    "        for i in range(u.shape[1]):\n",
    "            nn_dt[:, i] = autograd.grad(u[:, i], ts, grad_outputs=torch.ones_like(u[:, i]), create_graph=True)[0].squeeze()\n",
    "\n",
    "        pd = pdes(u, nn_dt, self.Si)\n",
    "        loss = nn.MSELoss()(pd, torch.zeros_like(pd))\n",
    "        return loss\n",
    "    \n",
    "    def loss(self, ts, data):\n",
    "        return self.data_loss(ts, data) + self.pde_loss(ts)\n",
    "    \n",
    "    def test(self, t):\n",
    "        #t = t.unsqueeze(0)\n",
    "        X_pred = self.nn.forward(t)\n",
    "        X_true = dict_to_vec(data, t)\n",
    "        print(X_pred.shape)\n",
    "        print(X_true.shape)\n",
    "        error_vec = torch.linalg.norm((X_true-X_pred),2)/torch.linalg.norm(X_true,2)\n",
    "        X_pred = X_pred.cpu().detach().numpy()\n",
    "        return X_pred, error_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([1, 7])\n",
      "Prediction: [-1.6499155  -1.5664932   0.11730391 -0.42615038  1.2028909  -0.30301777\n",
      "  1.4235082 ] \n",
      " Error: 0.9957432746887207\n",
      "Current guess for Si:  0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "NN = PINN([1, 20, 20, 20, 20, 20, 20, 7])\n",
    "params = list(NN.nn.parameters())\n",
    "optimizer = optim.Adam(NN.nn.parameters(), lr=0.001)\n",
    "\n",
    "'''Test Network works'''\n",
    "pred, err = NN.test(torch.tensor([1], device=device, dtype=torch.float32))\n",
    "print(f\"\"\"Prediction: {pred} \\n Error: {err}\"\"\")\n",
    "print(\"Current guess for Si: \", NN.Si.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_14612\\3976177905.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ts_train = torch.tensor(ts_train, device=device, dtype=torch.float32).reshape(-1,1)\n",
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_14612\\3976177905.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ts_test = torch.tensor(ts_test, device=device, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 18787.552734375, Si: 0.013522883877158165\n",
      "Epoch: 100, Loss: 19385.0546875, Si: 0.013351238332688808\n",
      "Epoch: 200, Loss: 22027.24609375, Si: 0.012042965739965439\n",
      "Epoch: 300, Loss: 20480.251953125, Si: 0.011882125400006771\n",
      "Epoch: 400, Loss: 20833.556640625, Si: 0.011268348433077335\n",
      "Epoch: 500, Loss: 19247.8828125, Si: 0.010700435377657413\n",
      "Epoch: 600, Loss: 19115.572265625, Si: 0.01038329117000103\n",
      "Epoch: 700, Loss: 16994.21875, Si: 0.01041802205145359\n",
      "Epoch: 800, Loss: 15498.8837890625, Si: 0.009785013273358345\n",
      "Epoch: 900, Loss: 19046.39453125, Si: 0.00953638181090355\n",
      "Epoch: 1000, Loss: 16133.6064453125, Si: 0.00956802163273096\n",
      "Epoch: 1100, Loss: 15366.216796875, Si: 0.008953992277383804\n",
      "Epoch: 1200, Loss: 16231.6484375, Si: 0.008937248960137367\n",
      "Epoch: 1300, Loss: 19329.80078125, Si: 0.008471050299704075\n",
      "Epoch: 1400, Loss: 17158.162109375, Si: 0.008559755980968475\n",
      "Epoch: 1500, Loss: 17218.439453125, Si: 0.008775832131505013\n",
      "Epoch: 1600, Loss: 16591.84765625, Si: 0.00819259975105524\n",
      "Epoch: 1700, Loss: 16707.744140625, Si: 0.008156482130289078\n",
      "Epoch: 1800, Loss: 18011.548828125, Si: 0.008521289564669132\n",
      "Epoch: 1900, Loss: 18160.921875, Si: 0.007978993467986584\n",
      "Epoch: 2000, Loss: 22522.02734375, Si: 0.007938574999570847\n",
      "Epoch: 2100, Loss: 17608.673828125, Si: 0.008033372461795807\n",
      "Epoch: 2200, Loss: 20235.42578125, Si: 0.007624552119523287\n",
      "Epoch: 2300, Loss: 16853.021484375, Si: 0.007973144762217999\n",
      "Epoch: 2400, Loss: 19061.021484375, Si: 0.007888752967119217\n",
      "Epoch: 2500, Loss: 16917.791015625, Si: 0.007779021747410297\n",
      "Epoch: 2600, Loss: 19662.34765625, Si: 0.007271477021276951\n",
      "Epoch: 2700, Loss: 19200.359375, Si: 0.007765335496515036\n",
      "Epoch: 2800, Loss: 19790.361328125, Si: 0.007746333722025156\n",
      "Epoch: 2900, Loss: 17244.390625, Si: 0.007848191075026989\n",
      "Epoch: 3000, Loss: 23313.9921875, Si: 0.007809959352016449\n",
      "Epoch: 3100, Loss: 18190.416015625, Si: 0.0076164971105754375\n",
      "Epoch: 3200, Loss: 19333.9765625, Si: 0.007381713483482599\n",
      "Epoch: 3300, Loss: 19957.8984375, Si: 0.007794945500791073\n",
      "Epoch: 3400, Loss: 18812.71484375, Si: 0.007738100364804268\n",
      "Epoch: 3500, Loss: 18307.46875, Si: 0.008013542741537094\n",
      "Epoch: 3600, Loss: 18349.87890625, Si: 0.007473362144082785\n",
      "Epoch: 3700, Loss: 18416.8671875, Si: 0.007995727472007275\n",
      "Epoch: 3800, Loss: 16984.533203125, Si: 0.00758679723367095\n",
      "Epoch: 3900, Loss: 19265.185546875, Si: 0.00754106929525733\n",
      "Epoch: 4000, Loss: 16648.083984375, Si: 0.007480214815586805\n",
      "Epoch: 4100, Loss: 17888.859375, Si: 0.0070999194867908955\n",
      "Epoch: 4200, Loss: 16509.046875, Si: 0.007020063232630491\n",
      "Epoch: 4300, Loss: 15317.9736328125, Si: 0.007168750278651714\n",
      "Epoch: 4400, Loss: 14772.58984375, Si: 0.007542415522038937\n",
      "Epoch: 4500, Loss: 18430.193359375, Si: 0.008038215339183807\n",
      "Epoch: 4600, Loss: 17848.9609375, Si: 0.0074386680498719215\n",
      "Epoch: 4700, Loss: 16429.662109375, Si: 0.007499226368963718\n",
      "Epoch: 4800, Loss: 19363.71484375, Si: 0.007673985790461302\n",
      "Epoch: 4900, Loss: 16638.109375, Si: 0.007224699482321739\n",
      "True Si:  0.0081\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ts_train = torch.tensor(ts_train, device=device, dtype=torch.float32).reshape(-1,1)\n",
    "ts_test = torch.tensor(ts_test, device=device, dtype=torch.float32)\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = NN.loss(ts_train, parms)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Si: {NN.Si.item()}\")\n",
    "\n",
    "print(\"True Si: \", Si_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
