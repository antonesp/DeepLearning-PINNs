{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\DeepLearning-PINNs\\Lucas\n",
      "dict_keys(['Meal_size', 'Steady_insulin', 'Bolus', 'D1', 'D2', 'I_sc', 'I_p', 'I_eff', 'G', 'G_sc'])\n"
     ]
    }
   ],
   "source": [
    "# Lucas/this_script.py\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "# Add the 'functions' folder to the Python path\n",
    "functions_dir = os.path.join(current_dir,'..', 'functions')\n",
    "sys.path.append(functions_dir)\n",
    "functions_dir = os.path.join(current_dir,'..', 'Mads')\n",
    "sys.path.append(functions_dir)\n",
    "\n",
    "# Now you can import the function\n",
    "from Load_data import custom_csv_parser2, custom_csv_parser\n",
    "from Load_data import data_split\n",
    "\n",
    "# Use the function\n",
    "data = custom_csv_parser2('../Patient2.csv')\n",
    "parms = custom_csv_parser('../Patient.csv')\n",
    "pde_keys = ['D1', 'D2', 'I_sc','I_p', 'I_eff', 'G', 'G_sc']\n",
    "patient_keys = ['tau1', 'tau2', 'Ci', 'p2', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "patient_keys_si = ['tau1', 'tau2', 'Ci', 'p2', 'Si', 'GEZI', 'EGP0', 'Vg', 'taum', 'tausc']\n",
    "\n",
    "X_train, X_test, ts_train, ts_test, ts = data_split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si0 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    '''Network'''\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1] ) for i in range(len(layers)-1)])\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'Initialization'\n",
    "        for i in range(len(layers) - 1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight, gain=1.0)\n",
    "            nn.init.zeros_(self.linears[i].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdes(u, nn_dt, parms, Si):\n",
    "    D1 = u[0]\n",
    "    D2 = u[1]\n",
    "    I_sc = u[2]\n",
    "    I_p = u[3]\n",
    "    I_eff = u[4]\n",
    "    G = u[5]\n",
    "    G_sc = u[6]\n",
    "    d = 0\n",
    "    pdes = np.zeros(len(u))\n",
    "    pdes[0] = nn_dt[0] + D1 / parms['taum'] - d\n",
    "    pdes[1] = nn_dt[1] - (D1 - D2) / parms['taum'] \n",
    "    pdes[2] = nn_dt[2] + I_sc / parms['tau1'] - u / (parms['tau1'] * parms['Ci'])\n",
    "    pdes[3] = nn_dt[3] - (I_sc - I_p) / parms['tau2']\n",
    "    pdes[4] = nn_dt[4] + parms['p2'] * I_eff - parms['p2'] * Si * I_p\n",
    "    pdes[5] = nn_dt[5] + (parms['GEZI'] + I_eff) * G - parms['EGP0'] - 1000 * D2 / (parms['Vg'] * parms['taum'])\n",
    "    pdes[6] = nn_dt[6] - (G - G_sc) / parms['tausc']\n",
    "\n",
    "    return pdes\n",
    "\n",
    "class PINN():\n",
    "    def __init__(self, layers):\n",
    "        self.iter = 0\n",
    "\n",
    "        self.Si = torch.tensor([Si0], requires_grad=True, device=device)\n",
    "        self.Si = nn.Parameter(self.Si)\n",
    "        self.nn = DNN(layers).to(device)\n",
    "        self.nn.register_parameter('Si', self.Si)\n",
    "\n",
    "        def data_loss(self, t, data, ts):\n",
    "            t_idx = ts[ts == t]\n",
    "            u = self.nn(t)  # Outputs 7 x 1 array\n",
    "            loss = 0\n",
    "            for i,key in enumerate(data.keys()):\n",
    "                loss += torch.mean((u[i] - data[key][t_idx])**2)\n",
    "            return loss\n",
    "\n",
    "        def pde_loss(self, t):\n",
    "            \n",
    "            t = t.clone()\n",
    "            t = t.requires_grad_(True)\n",
    "            u = self.nn(t)\n",
    "            \n",
    "            nn_dt = np.zeros(len(u))\n",
    "\n",
    "            for i in range(len(u)):\n",
    "                nn_dt[i] = autograd.grad(u[i], t, grad_outputs=torch.ones_like(u[i]), create_graph=True)[0]\n",
    "            pdes = pdes(u, nn_dt, data, self.Si)\n",
    "            loss = nn.MSELoss(pdes, torch.zeros_like(pdes))\n",
    "            return loss\n",
    "        \n",
    "        def loss(self, t, data):\n",
    "            return data_loss(self,t, data) + pde_loss(self, t)\n",
    "        \n",
    "        def closure(self, t):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.loss(t, data)\n",
    "            loss.backward()\n",
    "            self.iter += 1\n",
    "\n",
    "            if self.iter % 100 == 0:\n",
    "                print(\"Current loss\", loss)\n",
    "                print(self.Si.item())\n",
    "        \n",
    "        def test(self, t):\n",
    "            u_pred = self.nn(t)\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
