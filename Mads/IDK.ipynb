{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.init as init\n",
    "import torch.autograd as autograd\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from Load_data2 import custom_csv_parser\n",
    "from softadapt import SoftAdapt, LossWeightedSoftAdapt\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def grad(func, var):\n",
    "    '''\n",
    "    Computes the gradient of a function with respect to a variable.\n",
    "    Written by Engsig-Karup, Allan P. (07/05/2024).\n",
    "\n",
    "    Args:\n",
    "    func (torch.Tensor): Function to differentiate\n",
    "    var (torch.Tensor): Variable to differentiate with respect to\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Gradient of func with respect to var\n",
    "    '''\n",
    "    return torch.autograd.grad(func, var, grad_outputs=torch.ones_like(func), create_graph=True, retain_graph=True)[0] \n",
    "\n",
    "class PINN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=1, hidden_dim=20, output_dim=7, num_hidden=1):\n",
    "        super().__init__()     \n",
    "\n",
    "        # Define the layers\n",
    "        self.input = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.output = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for _ in range(num_hidden):\n",
    "            self.hidden.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim)) \n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "        # Define activation function\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Define loss function\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        # Define softplus as to not get negative values\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "        # Define patient parameters as tunable parameters\n",
    "        self.tau_1 =    Parameter(torch.tensor([47.0], requires_grad=True, device=device))       # [min]\n",
    "        self.tau_2 =    Parameter(torch.tensor([47.0], requires_grad=True, device=device))       # [min]\n",
    "        self.C_I =      Parameter(torch.tensor([18.0], requires_grad=True, device=device))         # [dL/min]\n",
    "        self.p_2 =      Parameter(torch.tensor([0.0005], requires_grad=True, device=device))       # [min^(-1)]\n",
    "        self.GEZI =     Parameter(torch.tensor([0.0005], requires_grad=True, device=device))      # [min^(-1)]\n",
    "        self.EGP_0 =    Parameter(torch.tensor([2.0], requires_grad=True, device=device))       # [(mg/dL)/min]\n",
    "        self.V_G =      Parameter(torch.tensor([300.0], requires_grad=True, device=device))        # [dL]\n",
    "        self.tau_m =    Parameter(torch.tensor([50.0], requires_grad=True, device=device))       # [min]\n",
    "        self.tau_sc =   Parameter(torch.tensor([6.0], requires_grad=True, device=device))       # [min]\n",
    "        self.S_I =      Parameter(torch.tensor([0.01], requires_grad=True, device=device))\n",
    "    \n",
    "\n",
    "    def forward(self, t):\n",
    "        u = self.activation(self.input(t))\n",
    "\n",
    "        for hidden_layer in self.hidden:\n",
    "            u = self.activation(hidden_layer(u))\n",
    "\n",
    "        u = self.output(u)\n",
    "\n",
    "        return u\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Initialize weights using Xavier initialization and biases to zero\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def MVP(self, t, u, d):\n",
    "        '''\n",
    "        Input:\n",
    "            x: Is the state tensor \n",
    "        '''\n",
    "\n",
    "        # Calculate the state vector\n",
    "        X = self.forward(t)\n",
    "\n",
    "        # Meal system\n",
    "        D_1 = X[:, 0]\n",
    "        D_2 = X[:, 1]\n",
    "        \n",
    "        # Insulin system\n",
    "        I_sc = X[:, 2]\n",
    "        I_p = X[:, 3]\n",
    "        I_eff = X[:, 4]\n",
    "        \n",
    "        # Glucose system        \n",
    "        G = X[:, 5]\n",
    "        G_sc = X[:, 6]\n",
    "                \n",
    "        tau_1 = self.tau_1\n",
    "        tau_2 = self.tau_2\n",
    "        C_I = self.C_I\n",
    "        p_2 = self.p_2\n",
    "        GEZI = self.GEZI\n",
    "        EGP_0 = self.EGP_0\n",
    "        V_G = self.V_G\n",
    "        tau_m = self.tau_m\n",
    "        tau_sc = self.tau_sc\n",
    "        S_I = self.S_I\n",
    "        \n",
    "        # Define gradients needed\n",
    "        D_1_t = grad(D_1, t)\n",
    "        D_2_t = grad(D_2, t)\n",
    "        I_sc_t = grad(I_sc, t)\n",
    "        I_p_t = grad(I_p, t)\n",
    "        I_eff_t = grad(I_eff, t)\n",
    "        G_t = grad(G, t)\n",
    "        G_sc_t = grad(G_sc, t)\n",
    "                \n",
    "        # Define our ODEs\n",
    "        Meal1 = D_1_t - d + (D_1 / tau_m)\n",
    "        Meal2 = D_2_t - (D_1 / tau_m) + (D_2 / tau_m)\n",
    "\n",
    "        Insulin1 = I_sc_t - (u/(tau_1*C_I)) + (I_sc / tau_1)\n",
    "        Insulin2 = I_p_t - (I_sc / tau_2) + (I_p / tau_2)\n",
    "        Insulin3 = I_eff_t + p_2 * I_eff - p_2 * S_I * I_p\n",
    "\n",
    "        Glucose1 = G_t + (GEZI + I_eff) * G - EGP_0 - ((1000 * D_2) / (V_G * tau_m))\n",
    "        Glucose2 = G_sc_t - (G / tau_sc) + (G_sc / tau_sc)\n",
    "                \n",
    "        # Save all the ODEs in a tensor\n",
    "        mvp = torch.stack([Meal1, Meal2, Insulin1, Insulin2, Insulin3, Glucose1, Glucose2], dim=1)\n",
    "\n",
    "        return mvp\n",
    "\n",
    "    def data_loss(self, t, data):\n",
    "        \n",
    "        \n",
    "        # Calculate the state vector\n",
    "        X = self.forward(t)\n",
    "        \n",
    "        # Glucose system        \n",
    "        G = X[:, 5]\n",
    "\n",
    "        # Scale the data\n",
    "        G_data = data[\"G\"].clone()\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss_data = self.loss_fn(G, G_data)\n",
    "\n",
    "        return loss_data\n",
    "\n",
    "    def loss(self, t_train, t_data, u, d, data):\n",
    "        ODE = self.MVP(t_train, u, d)\n",
    "        True_ODE = torch.zeros_like(ODE)\n",
    "        loss_ode = self.loss_fn(ODE, True_ODE)\n",
    "        print(ODE[:, 0])\n",
    "        \n",
    "        loss_data = self.data_loss(t_data, data)\n",
    "\n",
    "        return loss_ode, loss_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check for CUDA availability\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Define our model parameters\n",
    "    hidden_dim = 128\n",
    "    num_hidden_layers = 2\n",
    "\n",
    "    # Load data and pre-process\n",
    "    data = custom_csv_parser('../Patient3.csv')\n",
    "    n_data = len(data[\"G\"])\n",
    "\n",
    "    # Split data into training and validation\n",
    "    torch.manual_seed(42)\n",
    "    indices = torch.randperm(n_data)\n",
    "    n_train = int(n_data * 0.8)   # 80% training data\n",
    "\n",
    "    train_indices = indices[:n_train]\n",
    "    val_indices = indices[n_train:]\n",
    "\n",
    "    # Define  \n",
    "    T = data[\"t\"][-1]\n",
    "\n",
    "    # Split the data dictionary \n",
    "    data_train = {}\n",
    "    data_val = {}\n",
    "\n",
    "    for key in data.keys():\n",
    "        data_tensor = torch.tensor(data[key], device=device)          # Ensure data is a tensor\n",
    "        data_train[key] = data_tensor[train_indices]\n",
    "        data_val[key] = data_tensor[val_indices]\n",
    "\n",
    "    d_train = data_train[\"Meal\"].clone()\n",
    "    u_train = data_train[\"Insulin\"].clone()\n",
    "    t_train_data = data_train[\"t\"].clone().requires_grad_(True).reshape(-1, 1)\n",
    "    t_val = data_val[\"t\"].clone().requires_grad_(True).reshape(-1, 1)\n",
    "\n",
    "    n_col = 5000\n",
    "    t_train = torch.linspace(0, T, steps=n_col, device=device).requires_grad_(True).reshape(-1, 1)\n",
    "    n_fill = n_col - d_train.shape[0]\n",
    "    fill_tensor = torch.zeros(n_fill)\n",
    "    \n",
    "    d_train_fill = torch.zeros_like(fill_tensor, device=device)\n",
    "    u_train_fill = torch.zeros_like(fill_tensor, device=device)\n",
    "\n",
    "    d_train = torch.cat([d_train, d_train_fill])\n",
    "    u_train = torch.cat([u_train, u_train_fill])\n",
    "\n",
    "    # Define our model\n",
    "    model = PINN(hidden_dim=hidden_dim, num_hidden=num_hidden_layers).to(device)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "   \n",
    "    # Define number of epoch\n",
    "    num_epoch = 20000\n",
    "\n",
    "    # Setup arrays for saving the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "\n",
    "    # Setup SoftAdapt\n",
    "    softadapt_object = SoftAdapt(beta=0.1)\n",
    "    epochs_to_make_updates = 5\n",
    "    ODE_loss = []\n",
    "    data_loss = []\n",
    "    adapt_weight = [1.0, 1.0]   \n",
    "\n",
    "    # Define the true parameters\n",
    "    tau1_true = 49.0\n",
    "    tau2_true = 47.0\n",
    "    Ci_true = 20.1\n",
    "    p2_true = 0.0106\n",
    "    GEZI_true = 0.0022\n",
    "    EGP0_true = 1.33\n",
    "    Vg_true = 253.0\n",
    "    taum_true = 47.0\n",
    "    tausc_true = 5.0\n",
    "    Si_true = 0.0081\n",
    "\n",
    "    relative_errs = []\n",
    "\n",
    "    # Begin training our model\n",
    "    for epoch in range(num_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        loss_ode, loss_data = model.loss(t_train, t_train_data, u_train, d_train, data_train)\n",
    "        loss = adapt_weight[0] * loss_ode + adapt_weight[1] * loss_data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate softadapt weights\n",
    "        ODE_loss.append(loss_ode)\n",
    "        data_loss.append(loss_data)\n",
    "        if epoch % epochs_to_make_updates == 0 and epoch != 0:\n",
    "            adapt_weight = softadapt_object.get_component_weights(torch.tensor(ODE_loss), \n",
    "                                                                torch.tensor(data_loss),\n",
    "                                                                verbose=False,\n",
    "                                                                )\n",
    "            \n",
    "            ODE_loss = []\n",
    "            data_loss = []\n",
    "\n",
    "\n",
    "        # Create the console output and plot\n",
    "        if epoch % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                val_loss = model.data_loss(t_val, data_val)\n",
    "                sum_rel_errors = (abs(Si_true - model.S_I.item()) / Si_true \n",
    "                                + abs(tau1_true - model.tau_1.item()) / tau1_true \n",
    "                                + abs(tau2_true - model.tau_2.item()) / tau2_true \n",
    "                                + abs(Ci_true - model.C_I.item()) / Ci_true \n",
    "                                + abs(p2_true - model.p_2.item()) / p2_true \n",
    "                                + abs(GEZI_true - model.GEZI.item()) / GEZI_true \n",
    "                                + abs(EGP0_true - model.EGP_0.item()) / EGP0_true \n",
    "                                + abs(Vg_true - model.V_G.item()) / Vg_true \n",
    "                                + abs(taum_true - model.tau_m.item()) / taum_true \n",
    "                                + abs(tausc_true - model.tau_sc.item()) / tausc_true)\n",
    "                relative_errs.append(sum_rel_errors)\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            val_losses.append(val_loss.item())\n",
    "            # learning_rates.append(current_lr)\n",
    "\n",
    "            # Print training and validation loss\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}\")\n",
    "            # print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}, S_I: {S_I.item():.6f}\")\n",
    "            # print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, Val Loss: {val_loss.item():.6f}, GEZI: {GEZI.item():.6f}, S_I: {S_I.item():.6f}\")\n",
    "            # print(f\"Epoch {epoch}, Loss ODE: {loss_ode.item():.6f}, Loss data: {loss_data.item():.6f}\")#, S_I: {S_I.item():.6f}\")\n",
    "    \n",
    "    parameter_info = [\n",
    "        ('tau_1', 49.0),\n",
    "        ('tau_2', 47.0),\n",
    "        ('C_I', 20.1),\n",
    "        ('p_2', 0.0106),\n",
    "        ('GEZI', 0.0022),\n",
    "        ('EGP_0', 1.33),\n",
    "        ('V_G', 253.0),\n",
    "        ('tau_m', 47.0),\n",
    "        ('tau_sc', 5.0),\n",
    "        ('S_I', 0.0081)\n",
    "    ]\n",
    "\n",
    "    estimated_values = []\n",
    "    true_values = []\n",
    "    relative_errors = []\n",
    "\n",
    "    # Step 3: Compute estimated values and relative errors\n",
    "    with torch.no_grad():\n",
    "        for name, true_value in parameter_info:\n",
    "            raw_param = getattr(model, f'{name}')\n",
    "            est_value = raw_param.item()\n",
    "            rel_error = abs((est_value - true_value) / true_value)\n",
    "            estimated_values.append(est_value)\n",
    "            true_values.append(true_value)\n",
    "            relative_errors.append(rel_error)\n",
    "\n",
    "    # Step 4: Create and populate the PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Parameter\", \"Estimated Value\", \"True Value\", \"Relative Error\"]\n",
    "\n",
    "    for name, est_value, true_value, rel_error in zip(\n",
    "            [p[0] for p in parameter_info], estimated_values, true_values, relative_errors):\n",
    "        # Determine formatting based on the parameter's magnitude\n",
    "        if true_value >= 1.0:\n",
    "            est_str = f\"{est_value:.4f}\"\n",
    "            true_str = f\"{true_value:.4f}\"\n",
    "        else:\n",
    "            est_str = f\"{est_value:.6f}\"\n",
    "            true_str = f\"{true_value:.6f}\"\n",
    "        rel_err_str = f\"{rel_error:.2f}\"\n",
    "        table.add_row([name, est_str, true_str, rel_err_str])\n",
    "\n",
    "    # Align the columns\n",
    "    table.align[\"Parameter\"] = \"l\"\n",
    "    table.align[\"Estimated Value\"] = \"r\"\n",
    "    table.align[\"True Value\"] = \"r\"\n",
    "    table.align[\"Relative Error\"] = \"r\"\n",
    "\n",
    "    # Display the table\n",
    "    print(table)\n",
    "    print(relative_errs[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plot training and validation losses and learning rate\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    # # First subplot for losses\n",
    "    plt.subplot(2, 4, 1)\n",
    "    epochs = range(0, num_epoch, 100)  # Since we record losses every 100 epochs\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "\n",
    "    # Third subplot for glucose predictions\n",
    "    plt.subplot(2, 4, 2)\n",
    "    t_test = torch.linspace(0, T, 2500, device=device).reshape(-1, 1)\n",
    "    X_pred = model(t_test)\n",
    "    G_pred = X_pred[:, 5].detach().cpu().numpy()\n",
    "\n",
    "    plt.plot(t_test.cpu().numpy(), G_pred, label='Predicted Glucose (G)')\n",
    "    plt.plot(data[\"t\"], data[\"G\"], label='True Glucose (G)')\n",
    "    plt.xlabel('Time (t)')\n",
    "    plt.ylabel('Glucose Level')\n",
    "    plt.title('Predicted vs True Glucose Levels')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 3)\n",
    "    Gsc_pred = X_pred[:, 6].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), Gsc_pred , label='Predicted (Gsc)')\n",
    "    plt.plot(data[\"t\"], data[\"G_sc\"], label='True (Gsc)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 4)\n",
    "    D1_pred = X_pred[:, 0].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), D1_pred, label='Predicted (D1)')\n",
    "    plt.plot(data[\"t\"], data[\"D1\"], label='True Glucose (D1)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 5)\n",
    "    D2_pred = X_pred[:, 1].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), D2_pred, label='Predicted Glucose (D2)')\n",
    "    plt.plot(data[\"t\"], data[\"D2\"], label='True Glucose (D2)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 6)\n",
    "    Isc_pred = X_pred[:, 2].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), Isc_pred, label='Predicted (Isc)')\n",
    "    plt.plot(data[\"t\"], data[\"I_sc\"], label='True Glucose (Isc)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 7)\n",
    "    Ip_pred = X_pred[:, 3].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), Ip_pred, label='Predicted (Ip)')\n",
    "    plt.plot(data[\"t\"], data[\"I_p\"], label='True (Ip)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 4, 8)\n",
    "    Ieff_pred = X_pred[:, 4].detach().cpu().numpy()\n",
    "    plt.plot(t_test.cpu().numpy(), Ieff_pred, label='Predicted (Ieff)')\n",
    "    plt.plot(data[\"t\"], data[\"I_eff\"], label='True (Ieff)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
